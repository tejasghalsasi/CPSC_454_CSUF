Project: Dynamic Execution in Starfish
Author: Herodotos Herodotou
Date: September 22, 2011

Requirements
------------
1. Execution will work only with Hadoop versions 0.20.2 and 0.20.203.0
2. Execution will work only with jobs implementing the new API


Installation
------------
In order to execution MapReduce jobs in a cluster via Starfish you must
first set the global profiling parameters in bin/config.sh

The required parameters are:
   - SLAVES_BTRACE_DIR: The BTrace installation directory at the slave nodes
   - CLUSTER_NAME: A descriptive name for the cluster
   - PROFILER_OUTPUT_DIR: The local directory to place the output files


Execute a MapReduce job
-----------------------
There are two ways to execute a MapReduce job in the Hadoop cluster.

Method A: Using the bin/execute script
   Usage:
      ./bin/execute hadoop jar jarFile [mainClass] [genericOptions] args...
   Example:
      ./bin/execute hadoop jar hadoop-starfish-examples.jar wordcount input output

This method will submit the MapReduce job to the cluster and collect its
execution files upon completion. Afterwards, you may use the Starfish
Visualizer or bin/analyze script to analyze the execution of the job.

Note that the job execution will NOT incur any performance overhead when executed
using the bin/execute script.

Method B: Using the traditional ${HADOOP_HOME}/bin/hadoop script to execute
the MapReduce job and then bin/gather_results.sh to gather the execution files.

1. Execute the MapReduce job
   Usage:
      ${HADOOP_HOME}/bin/hadoop jar jarFile [mainClass] [genericOptions] args...
   Example:
      ${HADOOP_HOME}/bin/hadoop jar hadoop-starfish-examples.jar wordcount input output
   
2. Gather the execution files after the MapReduce job completes execution.
   Usage 1: Single job id:
      ./bin/gather_results.sh job_id
   Usage 2: Range of job ids:
      ./bin/gather_results.sh first_job_id last_job_id
   Examples:
      ./gather_results.sh job_201001052153_0021
      ./gather_results.sh job_201001052153_0021 job_201001052153_0025


